{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "# detect text boxes\n",
    "# detect text\n",
    "# return text and positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from dotmap import DotMap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from craft import CRAFT\n",
    "import imgproc\n",
    "import craft_utils\n",
    "\n",
    "from ocr_model import Model\n",
    "from ocr_dataset import RawDataset, AlignCollate\n",
    "from ocr_utils import CTCLabelConverter, AttnLabelConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "# end\n",
    "\n",
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "# end\n",
    "\n",
    "def init_craft():\n",
    "     # load net\n",
    "    net = CRAFT()     # initialize\n",
    "    str_trained_model_path = 'dmodel/craft_mlt_25k.pth'\n",
    "    net.load_state_dict(copyStateDict(torch.load(str_trained_model_path)))\n",
    "    \n",
    "    if True:\n",
    "        net = net.cuda()\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = False\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    return net\n",
    "# end\n",
    "\n",
    "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, canvas_size, show_time,mag_ratio):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    y, _ = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Post-processing\n",
    "    boxes = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text)\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "    \n",
    "    if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes\n",
    "# end\n",
    "\n",
    "def init_ocr(opt):\n",
    "    \"\"\" model configuration \"\"\"\n",
    "    if 'CTC' in opt['Prediction']:\n",
    "        converter = CTCLabelConverter(opt['character'])\n",
    "    else:\n",
    "        converter = AttnLabelConverter(opt['character'])\n",
    "    opt['num_class'] = len(converter.character)\n",
    "\n",
    "    if opt['rgb']:\n",
    "        opt['input_channel'] = 3\n",
    "    model = Model(opt)\n",
    "    print('model input parameters', opt['imgH'], opt['imgW'], opt['num_fiducial'], opt['input_channel'], opt['output_channel'],\n",
    "          opt['hidden_size'], opt['num_class'], opt['batch_max_length'], opt['Transformation'], opt['FeatureExtraction'],\n",
    "          opt['SequenceModeling'], opt['Prediction'])\n",
    "\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # load model\n",
    "    print('loading pretrained model from %s' % opt['saved_model'])\n",
    "    model.load_state_dict(torch.load(opt['saved_model']))\n",
    "\n",
    "    # prepare data. two demo images from https://github.com/bgshih/crnn#run-demo\n",
    "    # sai removed here\n",
    "\n",
    "    # predict\n",
    "    model.eval()\n",
    "    \n",
    "    return (model, converter)\n",
    "# end    \n",
    "\n",
    "def run_ocr(model, converter, image_tensors, opt):    \n",
    "    batch_size = image_tensors.size(0)\n",
    "    with torch.no_grad():\n",
    "        image = image_tensors.cuda()\n",
    "        # For max length prediction\n",
    "        length_for_pred = torch.cuda.IntTensor([opt['batch_max_length']] * batch_size)\n",
    "        text_for_pred = torch.cuda.LongTensor(batch_size, opt['batch_max_length'] + 1).fill_(0)\n",
    "\n",
    "    if 'CTC' in opt['Prediction']:\n",
    "        preds = model(image, text_for_pred).log_softmax(2)\n",
    "\n",
    "        # Select max probabilty (greedy decoding) then decode index to character\n",
    "        preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "        _, preds_index = preds.permute(1, 0, 2).max(2)\n",
    "        preds_index = preds_index.transpose(1, 0).contiguous().view(-1)\n",
    "        preds_str = converter.decode(preds_index.data, preds_size.data)\n",
    "\n",
    "    else:\n",
    "        preds = model(image, text_for_pred, is_train=False)\n",
    "\n",
    "        # select max probabilty (greedy decoding) then decode index to character\n",
    "        _, preds_index = preds.max(2)\n",
    "        preds_str = converter.decode(preds_index, length_for_pred)\n",
    "    # end\n",
    "\n",
    "    # print('-' * 80)\n",
    "    # print('image_path\\tpredicted_labels')\n",
    "    # print('-' * 80)\n",
    "    \n",
    "    pred_str_arr = []\n",
    "    \n",
    "    for index, pred in enumerate(preds_str):\n",
    "        if 'Attn' in opt['Prediction']:\n",
    "            pred = pred[:pred.find('[s]')]  # prune after \"end of sentence\" token ([s])\n",
    "        # end\n",
    "        pred_str_arr.append(pred)\n",
    "        # print('img_name<',index, '> pred<',pred, '>')\n",
    "    # end\n",
    "    \n",
    "    return pred_str_arr\n",
    "# end\n",
    "\n",
    "def preprocess_and_convert_to_tensorsarr(img_arr, tw, th):\n",
    "    image_tensors = []\n",
    "    for img in img_arr:\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize((tw, th), Image.BICUBIC)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img.sub_(0.5).div_(0.5)\n",
    "        image_tensors.append(img)\n",
    "    # end\n",
    "    \n",
    "    image_tensors = torch.cat([t.unsqueeze(0) for t in image_tensors], 0)\n",
    "    \n",
    "    return image_tensors\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, t1_name, t2_name):\n",
    "\n",
    "    bboxes = test_net(net, image, text_threshold, link_threshold, low_text, cuda, canvas_size, show_time, mag_ratio)\n",
    "\n",
    "    b_plot = True\n",
    "    len_boxes = len(bboxes)\n",
    "    crop_img_arr = []\n",
    "\n",
    "    for index, box in enumerate(bboxes):\n",
    "\n",
    "        box = box.astype(np.int32)\n",
    "        x = box[0][0]\n",
    "        w = box[1][0]-box[0][0]\n",
    "        y = box[0][1]\n",
    "        h = box[3][1]-box[0][1]\n",
    "\n",
    "        delta = 0\n",
    "        x = x - delta\n",
    "        y = y - delta\n",
    "        w = w + 2*delta\n",
    "        h = h + 2*delta\n",
    "\n",
    "        if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:\n",
    "            continue\n",
    "        # end                   \n",
    "\n",
    "        crop_img = image[y:y+h, x:x+w]   \n",
    "        # crop_img_arr.append(crop_img)\n",
    "        crop_img_arr.append(cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        if b_plot:    \n",
    "            plt.subplot(len_boxes, 1, index+1)\n",
    "            plt.imshow(crop_img)\n",
    "        # end\n",
    "\n",
    "    # end\n",
    "\n",
    "    if b_plot:\n",
    "        plt.show()\n",
    "    # end   \n",
    "    \n",
    "    if len_boxes == 0:\n",
    "        return {}\n",
    "    # end\n",
    "\n",
    "    image_tensors = preprocess_and_convert_to_tensorsarr(crop_img_arr, opt['imgW'], opt['imgH'])\n",
    "\n",
    "    pred_text_arr = run_ocr(ocr_model, ocr_converter, image_tensors, opt)\n",
    "    \n",
    "    if len(pred_text_arr) != len_boxes:\n",
    "        print('boxes len<', len_boxes, '> pred len<', len(pred_text_arr), '>')\n",
    "        # raise('pred and boxes dont match. Not expected to come here')\n",
    "        return {}\n",
    "    # end\n",
    "    \n",
    "    t1_name = t1_name.lower()\n",
    "    t2_name = t2_name.lower()\n",
    "    pos_out = {}\n",
    "    for index, pred_text in enumerate(pred_text_arr):\n",
    "        if pred_text == t1_name:\n",
    "            pos_out['t1'] = bboxes[index]\n",
    "        # end\n",
    "        \n",
    "        if pred_text == t2_name:\n",
    "            pos_out['t2'] = bboxes[index]\n",
    "        # end \n",
    "    # end\n",
    "    \n",
    "    return pos_out\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_scoreboard(image, bboxes):\n",
    "    \n",
    "    b_plot = False\n",
    "    len_boxes = len(bboxes)\n",
    "    crop_img_arr = []\n",
    "\n",
    "    for index, box in enumerate(bboxes):\n",
    "\n",
    "        box = box.astype(np.int32)\n",
    "        x = box[0][0]\n",
    "        w = box[1][0]-box[0][0]\n",
    "        y = box[0][1]\n",
    "        h = box[3][1]-box[0][1]\n",
    "\n",
    "        delta = 0\n",
    "        x = x - delta\n",
    "        y = y - delta\n",
    "        w = w + 2*delta\n",
    "        h = h + 2*delta\n",
    "\n",
    "        if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:\n",
    "            continue\n",
    "        # end                   \n",
    "\n",
    "        crop_img = image[y:y+h, x:x+w]   \n",
    "        # crop_img_arr.append(crop_img)\n",
    "        crop_img_arr.append(cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        if b_plot:    \n",
    "            plt.subplot(len_boxes, 1, index+1)\n",
    "            plt.imshow(crop_img)\n",
    "        # end\n",
    "\n",
    "    # end\n",
    "\n",
    "    if b_plot:\n",
    "        plt.show()\n",
    "    # end   \n",
    "    \n",
    "    if len_boxes == 0:\n",
    "        return {}\n",
    "    # end\n",
    "\n",
    "    image_tensors = preprocess_and_convert_to_tensorsarr(crop_img_arr, opt['imgW'], opt['imgH'])\n",
    "\n",
    "    pred_text_arr = run_ocr(ocr_model, ocr_converter, image_tensors, opt)\n",
    "    \n",
    "    if len(pred_text_arr) != len_boxes:\n",
    "        print('boxes len<', len_boxes, '> pred len<', len(pred_text_arr), '>')\n",
    "        # raise('pred and boxes dont match. Not expected to come here')\n",
    "        return []\n",
    "    # end\n",
    "    \n",
    "    return pred_text_arr    \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_scoreboard_rect(image, bboxes):\n",
    "    \n",
    "    b_plot = True\n",
    "    len_boxes = len(bboxes)\n",
    "    crop_img_arr = []\n",
    "\n",
    "    for index, box in enumerate(bboxes):\n",
    "\n",
    "        box = box.astype(np.int32)\n",
    "        x = box[0]\n",
    "        w = box[1]\n",
    "        y = box[2]\n",
    "        h = box[3]\n",
    "\n",
    "        delta = 0\n",
    "        x = x - delta\n",
    "        y = y - delta\n",
    "        w = w + 2*delta\n",
    "        h = h + 2*delta\n",
    "\n",
    "        if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:\n",
    "            continue\n",
    "        # end                   \n",
    "\n",
    "        crop_img = image[y:y+h, x:x+w]   \n",
    "        # crop_img_arr.append(crop_img)\n",
    "        crop_img_arr.append(cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "        if b_plot:    \n",
    "            plt.subplot(len_boxes, 1, index+1)\n",
    "            plt.imshow(crop_img)\n",
    "        # end\n",
    "\n",
    "    # end\n",
    "\n",
    "    if b_plot:\n",
    "        plt.show()\n",
    "    # end   \n",
    "    \n",
    "    if len_boxes == 0:\n",
    "        return {}\n",
    "    # end\n",
    "\n",
    "    image_tensors = preprocess_and_convert_to_tensorsarr(crop_img_arr, opt['imgW'], opt['imgH'])\n",
    "\n",
    "    pred_text_arr = run_ocr(ocr_model, ocr_converter, image_tensors, opt)\n",
    "    \n",
    "    if len(pred_text_arr) != len_boxes:\n",
    "        print('boxes len<', len_boxes, '> pred len<', len(pred_text_arr), '>')\n",
    "        # raise('pred and boxes dont match. Not expected to come here')\n",
    "        return []\n",
    "    # end\n",
    "    \n",
    "    return pred_text_arr    \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_scoreboard_pipeline(image, bboxes, ocr_model, ocr_converter, ocr_opt):  \n",
    "    \n",
    "    b_plot = True\n",
    "        \n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    len_boxes = len(bboxes)\n",
    "    if len_boxes == 0:\n",
    "        return []\n",
    "    # end\n",
    "\n",
    "    crop_img_arr = []\n",
    "    for index, box in enumerate(bboxes):\n",
    "        delta = 0\n",
    "        x = box[0] - delta\n",
    "        y = box[1] - delta\n",
    "        w = box[2] + 2*delta\n",
    "        h = box[3] + 2*delta\n",
    "\n",
    "        if x < 0 or y < 0 or x+w > image.shape[1] or y+h > image.shape[0]:\n",
    "            continue\n",
    "        # end                   \n",
    "\n",
    "        crop_img = img_gray[y:y+h, x:x+w]          \n",
    "        ret,thresh1 = cv2.threshold(crop_img,180,255,cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((2,2),np.uint8)\n",
    "        dilation = cv2.dilate(thresh1,kernel,iterations = 1)\n",
    "        ocr_image_input = crop_img\n",
    "        crop_img_arr.append(crop_img)\n",
    "        \n",
    "        if b_plot:    \n",
    "            plt.subplot(len_boxes, 1, index+1)\n",
    "            plt.imshow(ocr_image_input, cmap='gray')\n",
    "        # end\n",
    "    # end \n",
    "    \n",
    "    if b_plot:\n",
    "        plt.show()\n",
    "    # end   \n",
    "    \n",
    "    if len(crop_img_arr) == 0:\n",
    "        return []\n",
    "    # end\n",
    "    \n",
    "    image_tensors = preprocess_and_convert_to_tensorsarr(crop_img_arr, ocr_opt['imgW'], ocr_opt['imgH'])\n",
    "\n",
    "    pred_text_arr = run_ocr(ocr_model, ocr_converter, image_tensors, ocr_opt)       \n",
    "    return pred_text_arr    \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_threshold = 0.7\n",
    "low_text = 0.4\n",
    "link_threshold = 0.4\n",
    "canvas_size = 1280\n",
    "mag_ratio = 1.5\n",
    "cuda = True\n",
    "show_time = False\n",
    "no_of_matches_required_for_team_names = 20\n",
    "skip_delta_in_secs = 10\n",
    "i_print_frequency = 25\n",
    "max_pos_error = 2\n",
    "\n",
    "opt = DotMap({\n",
    "    'imgW': 100,\n",
    "    'imgH': 32,\n",
    "    'workers' : 4,\n",
    "    'batch_size' : 192,\n",
    "    'saved_model' : 'dmodel/TPS-ResNet-BiLSTM-Attn.pth',\n",
    "    'batch_max_length' : 25  ,\n",
    "    'rgb' : False,\n",
    "    'character' :'0123456789abcdefghijklmnopqrstuvwxyz',\n",
    "    'sensitive' : False ,\n",
    "    'PAD' : False,\n",
    "    'Transformation' : 'TPS',\n",
    "    'FeatureExtraction' : 'ResNet',\n",
    "    'SequenceModeling' : 'BiLSTM',\n",
    "    'Prediction' : 'Attn',\n",
    "    'num_fiducial' : 20,\n",
    "    'input_channel' : 1,\n",
    "    'output_channel' : 512,\n",
    "    'hidden_size' : 256,\n",
    "    'num_gpu' : torch.cuda.device_count()\n",
    "})\n",
    "\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "loading pretrained model from dmodel/TPS-ResNet-BiLSTM-Attn.pth\n"
     ]
    }
   ],
   "source": [
    "net = init_craft()\n",
    "ocr_model, ocr_converter = init_ocr(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imgproc.loadImage('/mnt/disks/d1/s/code/icehockeyaiengine/pipeline/tempcandelete_search/14-20190407-game11_source_0000000780.jpg')\n",
    "process_image(image, 'BVLY', 'WET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = imgproc.loadImage('/mnt/disks/d1/s/code/icehockeyaiengine/pipeline/tempcandelete/14-20190407-game11_source_0000001495.jpg')\n",
    "# image = imgproc.loadImage('/mnt/disks/d1/s/code/icehockeyaiengine/pipeline/tempcandelete_search/14-20190407-game11_source_0000000780.jpg')\n",
    "image = imgproc.loadImage('/mnt/disks/d1/s/code/icehockeyaiengine/pipeline/tempcandelete/albvscgy-icehockey-m-20190209_source_0000002147.jpg')# detect_scoreboard_rect(image, np.asarray([[396, 44, 60, 22], [502, 44, 20, 20], [842, 44, 54, 20], [754, 44, 18, 20], [560, 44, 36, 22], [678, 44, 54, 20]]))\n",
    "# detect_scoreboard_pipeline(image, np.asarray([[396, 44, 60, 22], [502, 44, 20, 20], [842, 44, 54, 20], [754, 44, 18, 20], [560, 44, 36, 22], [678, 44, 54, 20]]),ocr_model, ocr_converter, opt )\n",
    "detect_scoreboard_pipeline(image, np.asarray([[305, 39, 47, 34], [382, 39, 25, 34], [490, 39, 47, 34], [566, 39, 25, 34], [673, 39, 40, 34], [747, 39, 70, 34]]),ocr_model, ocr_converter, opt )\n",
    "# detect_scoreboard_pipeline(image, np.asarray([[312, 26, 90, 22], [504, 28, 18, 20], [620, 28, 54, 20], [814, 32, 10, 14], [874, 30, 42, 20], [947, 28, 74, 22]]), ocr_model, ocr_converter, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cgy', '0', 'alb', 't', '1st', '11124']\n",
      "{'t2_name': 'alb', 't1_score': 0, 't2_score': 1, 'period': 1, 'timer': '11:24', 't1_name': 'cgy'}\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../icehockeyaiengine/pipeline')\n",
    "\n",
    "from scoreboard_analyzer.templates.utils import match_template_and_get_values_common\n",
    "\n",
    "clip = VideoFileClip('/mnt/disks/d1/s/data/apra/source/albvscgy-icehockey-m-20190209_source.mp4')\n",
    "\n",
    "timestamp = 2824\n",
    "image = clip.get_frame(timestamp)\n",
    "pred_text_arr = detect_scoreboard_pipeline(image, np.asarray([[305, 39, 47, 34], [384, 39, 23, 34], [490, 39, 47, 34], [572, 39, 21, 34], [673, 39, 40, 34], [747, 39, 63, 34]]),ocr_model, ocr_converter, opt )    \n",
    "scoreboard_values = match_template_and_get_values_common(pred_text_arr)\n",
    "\n",
    "if len(pred_text_arr) != 0 and scoreboard_values == {} and (pred_text_arr[0] == 'cgy' or pred_text_arr[2] == 'alb'):\n",
    "    print('Prediction text exists but template match failed <'+str(timestamp)+'>')\n",
    "    print(pred_text_arr)\n",
    "# end\n",
    "\n",
    "print(pred_text_arr)\n",
    "print(scoreboard_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fullpath = '/mnt/disks/d1/s/data/apra/source/50-20190427-game11_source.mp4'\n",
    "v=cv2.VideoCapture(video_fullpath)\n",
    "i_offset_in_secs = 3178\n",
    "v.set(cv2.CAP_PROP_POS_MSEC, i_offset_in_secs*1000)\n",
    "ret, image = v.read()    \n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "detect_scoreboard_pipeline(image, np.asarray([[312, 26, 90, 22], [504, 28, 18, 20], [620, 28, 54, 20], [810, 28, 20, 20], [874, 30, 42, 20], [944, 28, 74, 22]]), ocr_model, ocr_converter, opt)\n",
    "# detect_scoreboard_pipeline(image, np.asarray([[312, 26, 90, 22], [504, 28, 18, 20], [620, 28, 54, 20], [814, 32, 10, 14], [874, 30, 42, 20], [944, 28, 74, 22]]), ocr_model, ocr_converter, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fullpath = '/mnt/disks/d1/s/data/apra/source/15-20190407-game12_source.mp4'\n",
    "t1_name = 'WAIN'\n",
    "t2_name = 'ADR'\n",
    "\n",
    "# net = init_craft()\n",
    "# ocr_model, ocr_converter = init_ocr(opt)\n",
    "\n",
    "v=cv2.VideoCapture(video_fullpath)\n",
    "\n",
    "i_counter = 0\n",
    "i_offset_in_secs = 350 # offset in seconds \n",
    "i_match_counter = 0\n",
    "\n",
    "pos_sec_arr = []\n",
    "pos_arr = []\n",
    "\n",
    "t1_min_box = [[10000 ,  10000],\n",
    "       [10000 ,  10000],\n",
    "       [10000  ,  10000 ],\n",
    "       [10000 ,  10000 ]]\n",
    "\n",
    "t2_min_box = [[10000 ,  10000],\n",
    "       [10000 ,  10000],\n",
    "       [10000  ,  10000 ],\n",
    "       [10000 ,  10000 ]]\n",
    "\n",
    "t1_max_box = [[0 ,  0],\n",
    "       [0 ,  0],\n",
    "       [0  ,  0 ],\n",
    "       [0 ,  0 ]]\n",
    "\n",
    "t2_max_box = [[0 ,  0],\n",
    "       [0 ,  0],\n",
    "       [0  ,  0 ],\n",
    "       [0 ,  0 ]]\n",
    "\n",
    "\n",
    "while True:\n",
    "    i_counter += 1\n",
    "    v.set(cv2.CAP_PROP_POS_MSEC, i_offset_in_secs*1000)\n",
    "    ret, frame = v.read()    \n",
    "    if ret != True:\n",
    "        break\n",
    "    # end\n",
    "    \n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    matched_out = process_image(frame, t1_name, t2_name)\n",
    "    \n",
    "    if 't1' in matched_out and 't2' in matched_out:\n",
    "        i_match_counter += 1\n",
    "        pos_arr.append(matched_out)\n",
    "        pos_sec_arr.append(i_offset_in_secs)\n",
    "        \n",
    "        for pt_index, px_pnt in enumerate(matched_out['t1']):\n",
    "            for xy_index, val in enumerate(px_pnt):\n",
    "                if t1_min_box[pt_index][xy_index] > val:\n",
    "                    t1_min_box[pt_index][xy_index] = val\n",
    "                # end\n",
    "                if t1_max_box[pt_index][xy_index] < val:\n",
    "                    t1_max_box[pt_index][xy_index] = val\n",
    "                # end\n",
    "            # end            \n",
    "        # end\n",
    "        \n",
    "        for pt_index, px_pnt in enumerate(matched_out['t2']):\n",
    "            for xy_index, val in enumerate(px_pnt):\n",
    "                if t2_min_box[pt_index][xy_index] > val:\n",
    "                    t2_min_box[pt_index][xy_index] = val\n",
    "                # end\n",
    "                if t2_max_box[pt_index][xy_index] < val:\n",
    "                    t2_max_box[pt_index][xy_index] = val\n",
    "                # end\n",
    "            # end            \n",
    "        # end\n",
    "        \n",
    "    # end\n",
    "    \n",
    "    if i_match_counter == no_of_matches_required_for_team_names:\n",
    "        break\n",
    "    # end        \n",
    "    \n",
    "    if i_counter % i_print_frequency == 0:\n",
    "        print('processed<', i_counter, '> offset<', i_offset_in_secs, '> matched<', i_match_counter, '>')\n",
    "    # end\n",
    "    \n",
    "    i_offset_in_secs += skip_delta_in_secs    \n",
    "# end\n",
    "\n",
    "print('Completed. Processed<', i_counter, '> offset<', i_offset_in_secs, '>')\n",
    "\n",
    "i_deviated_error_counter = 0\n",
    "\n",
    "for pt_index, px_pnt in enumerate(t2_min_box):\n",
    "    for xy_index, val in enumerate(px_pnt):\n",
    "        delta_pos = t2_max_box[pt_index][xy_index] - val\n",
    "        if delta_pos > max_pos_error:\n",
    "            i_deviated_error_counter += 1\n",
    "        # end\n",
    "    # end            \n",
    "# end\n",
    "\n",
    "for pt_index, px_pnt in enumerate(t1_min_box):\n",
    "    for xy_index, val in enumerate(px_pnt):\n",
    "        delta_pos = t1_max_box[pt_index][xy_index] - val\n",
    "        if delta_pos > max_pos_error:\n",
    "            i_deviated_error_counter += 1\n",
    "        # end\n",
    "    # end            \n",
    "# end\n",
    "\n",
    "print('Deviation Counter<', i_deviated_error_counter, '>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_arr[0]['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_arr[1]['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_arr[11]['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sec_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RepresentsIntTemp(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        if s == 'o':\n",
    "            return True\n",
    "        # end\n",
    "        return False\n",
    "    # end\n",
    "# end\n",
    "\n",
    "def GetInt(s):\n",
    "    try: \n",
    "        val = int(s)\n",
    "        return val\n",
    "    except ValueError:\n",
    "        if s == 'o':\n",
    "            return 0\n",
    "        # end\n",
    "        return -1\n",
    "    # end\n",
    "# end\n",
    "\n",
    "# 15-20190407-game12 50-20190427-game11\n",
    "video_fullpath = '/mnt/disks/d1/s/data/apra/source/15-20190407-game12_source.mp4'   \n",
    "t1_name = 'wain'\n",
    "t2_name = 'adr'\n",
    "\n",
    "# net = init_craft()\n",
    "# ocr_model, ocr_converter = init_ocr(opt)\n",
    "\n",
    "v=cv2.VideoCapture(video_fullpath)\n",
    "\n",
    "i_counter = 0\n",
    "i_offset_in_secs = 480 # offset in seconds \n",
    "i_match_counter = 0\n",
    "\n",
    "missed_secs_arr = []\n",
    "\n",
    "# b1 = np.array([[495, 23], [527, 23], [527, 55], [495, 55]]) # 492 32 40 40\n",
    "# b2 = np.array([[801, 23], [832, 23], [832, 55], [801, 55]]) # 746 32 40 40\n",
    "b1 = np.array([[492, 32], [532, 32], [532, 72], [492, 72]]) # 492 32 40 40\n",
    "b2 = np.array([[746, 32], [786, 32], [786, 72], [746, 72]]) # 746 32 40 40\n",
    "\n",
    "\n",
    "cur_score_index = -1\n",
    "score1_arr= []\n",
    "score2_arr = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    i_counter += 1\n",
    "    v.set(cv2.CAP_PROP_POS_MSEC, i_offset_in_secs*1000)\n",
    "    ret, frame = v.read()    \n",
    "    if ret != True:\n",
    "        break\n",
    "    # end\n",
    "    \n",
    "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # pred_text_arr = detect_scoreboard(frame, [pos_arr[0]['t1'], pos_arr[0]['t2']])\n",
    "    pred_text_arr = detect_scoreboard(frame, [b1, b2])\n",
    "    # print(pred_text_arr)\n",
    " \n",
    "    b_matched = True\n",
    "    if len(pred_text_arr) != 2 or RepresentsIntTemp(pred_text_arr[0]) == False or RepresentsIntTemp(pred_text_arr[1]) == False:\n",
    "        b_matched = False\n",
    "    # end\n",
    "                   \n",
    "    if b_matched:\n",
    "        i_match_counter += 1\n",
    "        score1 = GetInt(pred_text_arr[0])\n",
    "        score2 = GetInt(pred_text_arr[1])\n",
    "        \n",
    "        if cur_score_index == -1:\n",
    "            score1_arr.append(score1)\n",
    "            score2_arr.append(score2)\n",
    "            cur_score_index += 1     \n",
    "            cv2.imwrite('scorechanges/'+ filename.split('_source')[0] + '_'+str(i_offset_in_secs).zfill(10)+'.jpg', frame)\n",
    "        # end\n",
    "        \n",
    "        if score1_arr[cur_score_index] != score1 or score2_arr[cur_score_index] != score2:\n",
    "            score1_arr.append(score1)\n",
    "            score2_arr.append(score2)\n",
    "            cur_score_index += 1   \n",
    "            cv2.imwrite('scorechanges/'+ filename.split('_source')[0] + '_'+str(i_offset_in_secs).zfill(10)+'.jpg', frame)\n",
    "            print('Score Changed. <', score1, '> <', score2, '>')\n",
    "        # end        \n",
    "    else:\n",
    "        missed_secs_arr.append(i_offset_in_secs)        \n",
    "        cv2.imwrite('tempcandelete/frame_'+str(i_offset_in_secs).zfill(10)+'.jpg', frame)\n",
    "    # end\n",
    "            \n",
    "    if i_counter % i_print_frequency == 0:\n",
    "        print('processed<', i_counter, '> offset<', i_offset_in_secs, '> matched<', i_match_counter, '> missed<', len(missed_secs_arr), '>')\n",
    "    # end\n",
    "    \n",
    "    if i_counter > 1000000:\n",
    "        break\n",
    "    # end\n",
    "    \n",
    "    i_offset_in_secs += 10    \n",
    "# end\n",
    "\n",
    "print('Completed. Processed<', i_counter, '> offset<', i_offset_in_secs, '> matched<', i_match_counter, '> missed<', len(missed_secs_arr), '>')\n",
    "print(score1_arr)\n",
    "print(score2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_secs_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = '/mnt/disks/d1/s/data/apra/source/'\n",
    "filename = '43-20190425-game4_source.mp4'\n",
    "\n",
    "hours = 1\n",
    "minutes = 4\n",
    "seconds = 41\n",
    "i_offset_in_secs = hours*60*60 + minutes*60 + seconds\n",
    "\n",
    "v=cv2.VideoCapture(os.path.join(video_folder, filename))\n",
    "v.set(cv2.CAP_PROP_POS_MSEC, i_offset_in_secs*1000)\n",
    "ret, frame = v.read() \n",
    "cv2.imwrite('scoreboards/'+ filename.split('_source')[0] + '_'+str(i_offset_in_secs).zfill(10)+'.jpg', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RepresentsInt('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
